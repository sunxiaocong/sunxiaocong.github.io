---
layout: post
title: "Python 3.7 异步"
date: 2018-01-23
categories: Python
tags: [Python,异步]
image: http://gastonsanchez.com/images/blog/mathjax_logo.png
---

本文为Python 3.7 异步的官方文档中代码的一些理解 
个人对爬虫比较感兴趣变尝试使用Python 3.7 异步的一些新特性编写一个
异步多进程的爬虫小框架 [地址](https://github.com/daijiangtian/Widow)

<!-- more -->

## Coroutines and Tasks
### 运行一个不需要之前创建loop

```python
import asyncio

async def main():
    print('hello')
    await asyncio.sleep(1)
asyncio.run(main())
```

### 在main 函数中 上下是函数依旧是顺序调用的若

~~~python
import asyncio
import time

async def say_after(delay, what):
    await asyncio.sleep(delay)
    print(what)

async def main():
    print(f"started at {time.strftime('%X')}")

    await say_after(1, 'hello')
    await say_after(2, 'world')

    print(f"finished at {time.strftime('%X')}")

asyncio.run(main())
~~~

### 若希望将其异步需要使用asyncio.create_task()

~~~python
async def main():
    task1 = asyncio.create_task(
        say_after(1, 'hello'))

    task2 = asyncio.create_task(
        say_after(2, 'world'))

    print(f"started at {time.strftime('%X')}")

    # Wait until both tasks are completed (should take
    # around 2 seconds.)
    await task1
    await task2
    print(f"finished at {time.strftime('%X')}")
~~~

### gather

```python
import asyncio

async def factorial(name, number):
    f = 1
    for i in range(2, number + 1):
        print(f"Task {name}: Compute factorial({i})...")
        await asyncio.sleep(1)
        f *= i
    print(f"Task {name}: factorial({number}) = {f}")

async def main():
    # Schedule three calls *concurrently*:
    await asyncio.gather(
        factorial("A", 2),
        factorial("B", 3),
        factorial("C", 4),
    )

asyncio.run(main())
```

### 其中对多线程多进场也进行了封装

~~~python
import asyncio
import concurrent.futures

def blocking_io():
    # File operations (such as logging) can block the
    # event loop: run them in a thread pool.
    with open('/dev/urandom', 'rb') as f:
        return f.read(100)

def cpu_bound():
    # CPU-bound operations will block the event loop:
    # in general it is preferable to run them in a
    # process pool.
    return sum(i * i for i in range(10 ** 7))

async def main():
    loop = asyncio.get_running_loop()

    ## Options:

    # 1. Run in the default loop's executor:
    result = await loop.run_in_executor(
        None, blocking_io)
    print('default thread pool', result)

    # 2. Run in a custom thread pool:
    with concurrent.futures.ThreadPoolExecutor() as pool:
        result = await loop.run_in_executor(
            pool, blocking_io)
        print('custom thread pool', result)

    # 3. Run in a custom process pool:
    with concurrent.futures.ProcessPoolExecutor() as pool:
        result = await loop.run_in_executor(
            pool, cpu_bound)
        print('custom process pool', result)

asyncio.run(main())
~~~

### 对于需要对相应时间做限制使用 Timeouts

```python
async def eternity():
    # Sleep for one hour
    await asyncio.sleep(3600)
    print('yay!')

async def main():
    # Wait for at most 1 second
    try:
        await asyncio.wait_for(eternity(), timeout=1.0)
    except asyncio.TimeoutError:
        print('timeout!')

asyncio.run(main())
```

### asyncio 的方法
  * asyncio.current_task
    * 返回当前正在运行的实例
  * asyncio.all_task
    * 返回没有结束的全部Task实例

* Task的一些返回与方法

  * cancel()

    * 取消任务
  * cancelled()

    * 是否取消
  * done()

    * 是否结束
  * result()

    * 任务的返回结果 是一个迭代器
  * add_done_callback()

    * 任务回调函数
  * remove_done_callback()
  * get_stack
  * print_stack

## 异步中同步操作

### Lock

```python
lock = asyncio.Lock()

# ... later
async with lock:
    # access shared state
```

### Event

event 的set await 来控制程序的运行
```

import asyncio

async def waiter(event):
    print('waiting for it ...')
    await event.wait()
    print('... got it!')

async def main():
    # Create an Event object.
    event = asyncio.Event()

    # Spawn a Task to wait until 'event' is set.
    waiter_task = asyncio.create_task(waiter(event))

    # Sleep for 1 second and set the event.
    await asyncio.sleep(1)
    event.set()
    print(1)
    # Wait until the waiter task is finished.
    # await waiter_task

asyncio.run(main())
```

### Conditon

```python
cond = asyncio.Condition()

# ... later
async with cond:
    await cond.wait()
```

### semaphore

```python
sem = asyncio.Semaphore(10)

# ... later
async with sem:
    # work with shared resource
```

## 队列

~~~python
import asyncio
import random
import time


async def worker(name, queue):
    while True:
        # Get a "work item" out of the queue.
        sleep_for = await queue.get()

        # Sleep for the "sleep_for" seconds.
        await asyncio.sleep(sleep_for)

        # Notify the queue that the "work item" has been processed.
        queue.task_done()

        print(f'{name} has slept for {sleep_for:.2f} seconds')


async def main():
    # Create a queue that we will use to store our "workload".
    queue = asyncio.Queue()

    # Generate random timings and put them into the queue.
    total_sleep_time = 0
    for _ in range(20):
        sleep_for = random.uniform(0.05, 1.0)
        total_sleep_time += sleep_for
        queue.put_nowait(sleep_for)

    # Create three worker tasks to process the queue concurrently.
    tasks = []
    for i in range(3):
        task = asyncio.create_task(worker(f'worker-{i}', queue))
        tasks.append(task)

    # Wait until the queue is fully processed.
    started_at = time.monotonic()
    await queue.join()
    total_slept_for = time.monotonic() - started_at

    # Cancel our worker tasks.
    for task in tasks:
        task.cancel()
    # Wait until all worker tasks are cancelled.
    await asyncio.gather(*tasks, return_exceptions=True)

    print('====')
    print(f'3 workers slept in parallel for {total_slept_for:.2f} seconds')
    print(f'total expected sleep time: {total_sleep_time:.2f} seconds')


asyncio.run(main())
~~~
