---
layout: post
title: "基于上游数据库日志同步采集"
date: 2019-01-22
categories: 大数据
tags: [数据采集,Python]
image: http://gastonsanchez.com/images/blog/mathjax_logo.png
---

在日志的上下游需要中转时如果采用开启一个http服务用请求的方式当设计的表多了管理起来就非常麻烦
因此这里采用直接对数据库访问，采集实时的数据本文包含了　mysql　binlog　采集　mongo　oplog　采集
postgres　wal　采集　

Github地址:https://github.com/daijiangtian/db-transfer

<!-- more -->

### MYSQL

binlog日志用于记录所有更新了数据或者已经潜在更新了数据（例如，没有匹配任何行的一个DELETE）的所有语句。语句以“事件”的形式保存，它描述数据更改。

因为有了数据更新的binlog，所以可以用于实时备份，与master/slave主从复制结合。

#### Binlog操作

```
binlog的删除可以手工删除或自动删除：
a）自动删除binlog
通过binlog参数（expire_logs_days ）来实现mysql自动删除binlog
mysql> show binary logs;
mysql> show variables like 'expire_logs_days';      //该参数表示binlog日志自动删除/过期的天数，默认值为0，表示不自动删除
mysql> set global expire_logs_days=3;        //表示日志保留3天，3天后就自动过期。
b）手工删除binlog
mysql> reset master;        //删除master的binlog，即手动删除所有的binlog日志
mysql> reset slave;          //删除slave的中继日志
mysql> purge master logs before '2012-03-30 17:20:00';         //删除指定日期以前的日志索引中binlog日志文件
mysql> purge master logs to 'binlog.000002';       //删除指定日志文件的日志索引中binlog日志文件

mysql> set sql_log_bin=1/0;       //如果用户有super权限，可以启用或禁用当前会话的binlog记录
mysql> show master logs;          //查看master的binlog日志列表
mysql> show binary logs;           //查看master的binlog日志文件大小
mysql> show master status;     //用于提供master二进制日志文件的状态信息
mysql> show slave hosts;        //显示当前注册的slave的列表。不以--report-host=slave_name选项为开头的slave不会显示在本列表中

mysql> flush logs;     //产生一个新的binlog日志文件

```

#### Binlog日志格式

Mysql binlog日志有三种格式，分别是Statement、MiXED、ROW

##### Statement

每一条会修改数据的sql都会记录在binlog中
优点：不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能。(相比row能节约多少性能与日志量，这个取决于应用的SQL情况，正常同一条记录修改或者插入row格式所产生的日志量还小于Statement产生的日志量，但是考虑到如果带条件的update操作，以及整表删除，alter表等操作，ROW格式会产生大量日志，因此在考虑是否使用ROW格式日志时应该跟据应用的实际情况，其所产生的日志量会增加多少，以及带来的IO性能问题。)
缺点：由于记录的只是执行语句，为了这些语句能在slave上正确运行，因此还必须记录每条语句在执行的时候的一些相关信息，以保证所有语句能在slave得到和在master端执行时候相同 的结果。另外mysql 的复制,像一些特定函数功能，slave可与master上要保持一致会有很多相关问题(如sleep()函数， last_insert_id()，以及user-defined functions(udf)会出现问题).

使用以下函数的语句也无法被复制：
* LOAD_FILE()
* UUID()
* USER()
* FOUND_ROWS()
* SYSDATE() (除非启动时启用了 --sysdate-is-now 选项)

同时在INSERT ...SELECT 会产生比 RBR 更多的行级锁

##### Row

不记录sql语句上下文相关信息，仅保存哪条记录被修改
优点： binlog中可以不记录执行的sql语句的上下文相关的信息，仅需要记录那一条记录被修改成什么了。所以rowlevel的日志内容会非常清楚的记录下每一行数据修改的细节。而且不会出现某些特定情况下的存储过程，或function，以及trigger的调用和触发无法被正确复制的问题
缺点:所有的执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，这样可能会产生大量的日志内容,比如一条update语句，修改多条记录，则binlog中每一条修改都会有记录，这样造成binlog日志量会很大，特别是当执行alter table之类的语句的时候，由于表结构修改，每条记录都发生改变，那么该表每一条记录都会记录到日志中。

##### Mixedlevel

是以上两种level的混合使用，一般的语句修改使用statment格式保存binlog，如一些函数，statement无法完成主从复制的操作，则采用row格式保存binlog,MySQL会根据执行的每一条具体的sql语句来区分对待记录的日志形式，也就是在Statement和Row之间选择一种.新版本的MySQL中队row level模式也被做了优化，并不是所有的修改都会以row level来记录，像遇到表结构变更的时候就会以statement模式来记录。至于update或者delete等修改数据的语句，还是会记录所有行的变更。

Mixed日志说明：
在slave日志同步过程中，对于使用now这样的时间函数，MIXED日志格式，会在日志中产生对应的unix_timestamp()*1000的时间字符串，slave在完成同步时，取用的是sqlEvent发生的时间来保证数据的准确性。另外对于一些功能性函数slave能完成相应的数据同步，而对于上面指定的一些类似于UDF函数，导致Slave无法知晓的情况，则会采用ROW格式存储这些Binlog，以保证产生的Binlog可以供Slave完成数据同步。

### MONGO

oplog是local库下的一个固定集合，Secondary就是通过查看Primary 的oplog这个集合来进行复制的。每个节点都有oplog，记录这从主节点复制过来的信息，这样每个成员都可以作为同步源给其他节点。
Oplog 可以说是Mongodb Replication的纽带了。

#### OPLOG数据结构

```
    db.oplog.rs.find().skip(1).limit(1).toArray()
```

- ts: 8字节的时间戳，由4字节unix timestamp + 4字节自增计数表示。这个值很重要，在选举(如master宕机时)新primary时，会选择ts最大的那个secondary作为新primary
- op：1字节的操作类型
- "i"： insert
- "u"： update
- "d"： delete
- "c"： db cmd
- "db"：声明当前数据库 (其中ns 被设置成为=>数据库名称+ '.')
- "n": no op,即空操作，其会定期执行以确保时效性
- ns：操作所在的namespace
- o：操作所对应的document，即当前操作的内容（比如更新操作时要更新的的字段和值）
- o2: 在执行更新操作时的where条件，仅限于update时才有该属性

#### 查看oplog　日志信息

```
    db.printReplicationInfo()
```

- configured oplog size： oplog文件大小
- log length start to end: oplog日志的启用时间段
- oplog first event time: 第一个事务日志的产生时间
- oplog last event time: 最后一个事务日志的产生时间
- now: 现在的时间


### POSTGRES

WAL即Write-Ahead Logging,预写式日志（WAL）是保证数据完整性的一种标准方法。WAL的中心概念是数据文件（存储着表和索引）的修改必须在这些动作被日志记录之后才被写入，即在描述这些改变的日志记录被刷到持久存储以后。如果我们遵循这种过程，我们不需要在每个事务提交时刷写数据页面到磁盘，因为我们知道在发生崩溃时可以使用日志来恢复数据库：任何还没有被应用到数据页面的改变可以根据其日志记录重做（这是前滚恢复，也被称为REDO）。WAL 的中心思想是先写日志，再写数据，数据文件的修改必须发生在这些修改已经记录在日志文件中之后。

#### WAL

通过伪装成改集群分区节点可消费WAL日志达到数据同步的目的

#### 配置
在下列文件添加配置

pb_hdb.conf
```
    local replication testrepl trust
```

postgresql.conf
```
```
    wal_level = logical
    max_wal_senders = 3
    max_replication_slots = 3
```
