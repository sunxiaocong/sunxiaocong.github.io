---
layout: post
title: "日志SDK结构介绍"
date: 2019-02-15
categories: 随笔
tags: [随笔]
image: http://gastonsanchez.com/images/blog/mathjax_logo.png
---

系统日志聚合服务由syslog服务器(Rsyslog)或Fluentd服务器收集程序运行时生成的日志，经过相应处理，再次转发给Elasticsearch存储起来，然后在Kibana上对Elasticsearch中的数据进行搜索、查询、分析等操作。


<!-- more -->


## 接入实例

### 聊天服务接入系统日志

现在，以内网Rancher（ [http://192.168.5.84:8080](http://192.168.5.84:8080) ）上的`dq2-chat-http`服务为例，更清楚地阐释如何将一个新项目接入系统日志聚合功能。该项目的内网gitlab源码地址为：https://gitlab.dianchu.cc/go_chaos/chaos_chat 。

#### 项目代码目录结构

```python
.
│  conf.yml       # yaml格式的配置文件，即前面的conf.yml
│  DockerfileGrpc # Dockerfile文件
│  DockerfileHttp # Dockerfile文件
├─src
│  │  route.py # 实现某种功能，调用到logger.py
│  │  ...      # 其它文件
│  │
│  │
│  └─tool
│          logger.py  # logger的初始化
│          ...        # 其它文件
│
└─...   # 其它文件
```

#### 需要关注的文件
__现在，要弄清如何实现系统日志聚合功能，需要关注一些特定的文件：__

* `/DockerfileGrpc`：`Dockerfile`文件。
* `/DockerfileHttp`：`Dockerfile`文件。
* `/conf.yml`：yaml格式的配置文件，即前面的`conf.yml`。
* `/src/tool/logger.py`：与前面的`logger.py`相同，用于logger的初始化。
* `/src/route.py`：实现某种功能，调用到`logger.py`。


#### 项目接入系统日志聚合
__`/DockerfileGrpc`及`/DockerfileHttp`中均有以下命令。此命令为必要，请加入自己项目中的Dockerfile中。__

```dockerfile
RUN pip install --trusted-host pypi.dianchu.cc -i http://pypi.dianchu.cc/simple/ dc-log-output>=1.1.1
```

__`/conf.yml`：日志输出配置文件，新项目请修改`dq2_chat`为相应的标签。此文件为必要，请自行创建。__

```yaml
logging:
  version: 1

  formatters:
    fluent_fmt:
      '()': log_output_py.log_adapter.EventFormatter

  handlers:
    console:
      class : logging.StreamHandler
      level: DEBUG
      formatter: fluent_fmt
      stream: ext://sys.stdout
    syslog:
      class: log_output_py.log_adapter.SysLogHandler
      level: DEBUG
      formatter: fluent_fmt
      host: 192.168.7.99
      port: 514

  loggers:
    '': # root logger
      handlers: [console]
      level: DEBUG
      propagate: False
    'dq2_chat': # fluentd_test请换成自己对应的项目的名字
      handlers: [syslog]  #支持多个输出，设为[console,syslog]表示控制台也输出
      level: DEBUG
      propagate: False
```

__`/src/tool/logger.py`：logger的初始化。新项目请修改`dq2_chat`为相应的标签。此文件为必要，请自行创建。__

```python
见接入流程-1.1.4节 初始化logger
```

#### 在项目中输出日志
要使用`logger`，需要先从`logger`模块（`logger.py`）中导入`logger`对象（`logger = log_init()`）：

```python
from src.tool.logger import logger
```

之后，在代码中，可以使用下列的语句输出日志（参数列表见：[日志参数说明](#日志参数说明)）：

```python
logger.debug(msg[, *args[, **kwargs]])
logger.info(msg[, *args[, **kwargs]])
logger.warning(msg[, *args[, **kwargs]])
logger.error(msg[, *args[, **kwargs]])
logger.critical(msg[, *args[, **kwargs]])
```

python中，logging级别如下。如果要设置更多级别，可以参照其数值进行设置。此例中，logging的级别已在`conf.yml`中配置好，为` level: DEBUG`。级别大于或等于（即数值多于或等于）设置的logging级别的日志，才会被打印出来。此例中，5个级别的日志都会被打印出来。

|  Level   | Numeric Value |
| :------: | :-----------: |
| CRITICAL |      50       |
|  ERROR   |      40       |
| WARNING  |      30       |
|   INFO   |      20       |
|  DEBUG   |      10       |
|  NOTSET  |       0       |


__`/src/route.py`中与logger有关的语句为：__

```python
Line 22: from src.tool.logger import logger

Line 70: logger.error(u'参数错误', trace_id=trace_id, extra={"ip": ip, "params": params}, tag="chaos_chat_err")

Line 72: logger.error(u'数据库操作失败', trace_id=trace_id, exc_info=e, tag="chaos_chat_err")

Line 76: logger.error(u'未知错误', trace_id=trace_id, exc_info=e, tag="chaos_chat_err")

Line 90: logger.info(resp, trace_id=trace_id, tag="chaos_chat_resp", extra={"params": req_msg, "ip": ip, "spend": spend, "metadata": grpc_metadata})

Line 93:logger.info(resp, trace_id=trace_id, tag="chaos_chat_resp", extra={"params": req_msg, "ip": ip, "spend": spend})
```

上述即为dq2-chat-http项目使用系统日志聚合的实例。当新增加的项目需要接入系统日志聚合时，请参照此例设置，即可在Kibana中查询到输出的日志。

## 接入地址

系统日志聚合地址包括四类：

* syslog：接收并转发日志
* Fluentd：接收并转发日志（列出供有需要者查阅）
* Elasticsearch：存储日志（地址不列出）
* Kibana：查询日志（查询系统日志地址）

## API参考

### Python项目

#### 日志输出函数

`logger`为`logger.py`初始化后返回的对象。

```python
logger.debug(msg[, *args[, **kwargs]])     # DEBUG级别日志
logger.info(msg[, *args[, **kwargs]])      # INFO级别日志
logger.warning(msg[, *args[, **kwargs]])   # WARNING级别日志
logger.error(msg[, *args[, **kwargs]])     # ERROR级别日志
logger.critical(msg[, *args[, **kwargs]])  # CRITICAL级别日志
```

#### 日志参数说明

__日志输出函数参数及日志字段列表：__

| 参数名称   | 日志字段 | 参数说明                                   | 参数类型                                                     | 必传 | 其它说明                                   |
| ---------- | -------- | ------------------------------------------ | ------------------------------------------------------------ | ---- | :--------------------------------------- |
| 无  | level_name | 日志级别（日志类型分类）                   | int<br> (10:DEBUG<br> 20:INFO <br>30:WARNING<br> 40:ERROR <br>50:CRITICAL) | 是   | 调用不同级别的日志输出函数时，自动生成。 |
| 无   | log_time | 日志时间                                   | datetime                                                     | 是   | 自动生成                                 |
| 无   | filename | 文件名                                     | string                                                       | 是   | 自动生成                                 |
| 无 | module | 模块名                                     | string                                                       | 是   | 自动生成                                 |
| 无    | line_no | 行号                                       | int                                                          | 是   | 自动生成                                 |
| 无  | func_name | 函数名                                     | string                                                       | 是   | 自动生成                                 |
| msg | message | 日志内容                                   | string（位置参数）                                                 | 否   | 需手动填写                               |
| tag        | tag | 内部日志标签（用于区分同一服务的不同主题） | string（可变参数）                                                 | 是   | 需手动填写                               |
| trace_id   | trace_id | 追踪标识（用于追踪服务调用链）             | string（可变参数）                                                 | 否   | 需手动填写                               |
| exc_info   | exc_info | 异常信息                                   | string（可变参数）                                                 | 否   | 需指定异常或错误信息的对象               |
| stack_info | stack_info | 调用堆栈                                   | string（可变参数）                                                 | 否   | exc_info有异常时自动生成                 |
| extra | extra | 扩展字段 | dict（包裹关键字参数） | 否 | 可添加任意字段。__!!扩展字段请不要使用动态生成的json key，必须使用固定的key，否则会造成字段过多，影响日志服务器性能。__ |
|无|@fluentd_tag|全局日志标签（同一服务使用唯一标签，如聊天服务为dq2_chat）|string|是|由初始化函数的logger_name参数指定|

### Go语言项目

#### 日志输出函数

`cLog`为包`gitlab.dianchu.cc/chaos_go_sdk/log_out_sdk_go`的别名，可以任意指定。

```go
cLog.Logger.InitLogger(toStd bool, toSyslog bool, logLevel string, syslogIP string, syslogPort string, logMode string, loggerName string)  // 全局必须且仅需进行一次初始化

cLog.Debug(logRecord *LogRecord)     // DEBUG级别日志
cLog.Info(logRecord *LogRecord)      // INFO级别日志
cLog.Warning(logRecord *LogRecord)   // WARNING级别日志
cLog.Error(logRecord *LogRecord)     // ERROR级别日志
cLog.Critical(logRecord *LogRecord)  // CRITICAL级别日志
cLog.Fixed(logRecord *LogRecord)     // FIXED级别日志
```

#### 日志参数说明

__初始化函数参数说明：__

见接入流程-1.2.3节`初始化函数参数列表`

__日志输出函数参数及日志字段列表：__

日志输出函数传入参数为一个结构体`LogRecord`。

```go
// 允许设置的log内容
type LogRecord struct {
	Message    string    `json:"message,omitempty"`
	Tag        string    `json:"tag"`
	TraceId    string    `json:"trace_id,omitempty"`
	ExcInfo    string    `json:"exc_info,omitempty,string"`
	Extra      *ExtField `json:"extra,omitempty"`
}
```


| 参数名称          | 日志字段   | 参数说明 | 参数类型 | 必传 | 其它说明 |
| ----------------- | ---------- | -------- | -------- | ---- | ---- |
|         无          | level_name | 日志级别（日志类型分类） | int<br> (10:DEBUG<br> 20:INFO <br>30:WARNING<br> 40:ERROR <br>50:CRITICAL<br>100:FIXED) | 是 | 调用不同级别的日志输出函数时，自动生成。 |
|          无         | log_time   | 日志时间 | string | 是 | 自动生成 |
|            无       | filename   | 文件名 | string | 是 | 自动生成 |
|            无       | module     | 模块名 | string | 是 | 自动生成 |
|              无     | line_no   | 行号 | int | 是 | 自动生成 |
|              无     | func_name  | 函数名 | string | 是 | 自动生成 |
|        logRecord.Message           | message    | 日志内容 | string | 是 | 需手动填写 |
| logRecord.Tag | tag        | 内部日志标签（同一服务允许多个不同的标签，用于区分不同主题） | string | 否 | 需手动填写，默认值为root |
| logRecord.TraceId | trace_id   | 追踪标识（用于追踪服务调用链） | string | 否 | 需手动填写 |
| logRecord.ExcInfo | exc_info   | 异常信息 | string | 否 | 需指定异常或错误信息的对象 |
| 无 | stack_info | 调用堆栈 | string | 否 | exc_info有异常时自动生成 |
| LogRecord.Extra | extra | 扩展字段 | *ExtField | 否 | 可添加任意字段。其中，`type ExtField map[string]interface{}`。__!!扩展字段请不要使用动态生成的json key，必须使用固定的key，否则会造成字段过多，影响日志服务器性能。__ |
|无|@fluentd_tag|全局日志标签（同一服务使用唯一标签，如聊天服务为dq2_chat）|string|是|由初始化函数InitLogger的loggerName参数指定|


## 常见问题
### Kibana无法创建索引模式
在Kibana上创建索引模式（`Index Pattern`）时，需要在Elasticsearch已经存储有相关数据。如果报`Unable to fetch mapping. Do you have indices matching the pattern?`，且下方没有Create键或者Create键是暗的，说明，该标签的日志或数据并没有传送给Elasticsearch，或者Elasticsearch中从始至终尚没有相关索引的数据存入。请检查你的索引名是否正确，或者你的项目是否正常运行。若依然无法创建，可直接询问负责系统日志聚合的人员。

### Kibana中查询不到早期的日志
由于日志数据存储需要占用一定的磁盘空间，而目前各环境服务器的存储均有限，为避免影响查询速度或因服务器存储不够导致宕机，我们将定期删除Elasticsearch中过期的日志数据。如果你的日志需要保留得久一点，请联系相关负责人员。各环境日志数据在Elasticsearch中的默认保存期限如下：

| 环境         | 默认保存期限 |
| :--------- | :----- |
| 内网测试环境     | 10天    |
| UCloud测试环境 | 15天    |
| UCloud生产环境 | 50天    |
| 阿里云测试环境    | 15天    |
| 阿里云生产环境    | 30天    |
| 海外生产环境    | 30天    |
| 法兰克福生产环境    | 30天    |

## 更新说明

* 2017.10.27 - v1.0
  系统日志聚合接入文档。
* 2017.11.16 - v1.1
  完善接入流程与描述。
* 2017.11.29 - v1.2
  在接入文档中添加`更新说明`和`技术支持`。
* 2017.12.13 - v1.3
  添加`go语言项目接入流程`和`Kibana查询日志简要图示`。
* 2018.01.10 - v1.4.0
  添加`日志数据默认保存期限说明`和`Kibana日志查询索引模式创建图示`。
* 2018.04.09 - v2.0.0
  升级系统日志聚合方案并更新日志输出SDK。
* 2018.06.26 - v3.0.0
  升级系统日志聚合方案为SDK->Rsyslog->Elasticsearch，并更新日志输出SDK（v1.3.0）。添加了缓存队列、失败写文件机制和批量发送，达到日志异步发送和消峰效果，并提高了发送效率，减少对服务本身的影响。
* 2018.07.06 - v3.0.1
  更新Python日志输出SDK（v1.3.1）：主进程退出时，自动清理环境并关闭日志扫描线程。
* 2018.07.17 - v3.0.2
  更新Go日志输出SDK（v2.1.0）：添加了缓存队列、失败写文件机制和批量发送，达到日志异步发送和消峰效果，并提高了发送效率，减少对服务本身的影响。



> Note
> 欢迎大家在下面留下对文档的修改建议。

