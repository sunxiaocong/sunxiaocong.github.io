---
layout: post
title: "主成分分析法  pca"
date: 2019-03-03
categories: 数据分析
tags: [Python,数据挖掘]
image: http://gastonsanchez.com/https://github.com/daijiangtian/NoteBook/blob/master/机器学习/时间序列/https://github.com/daijiangtian/NoteBook/blob/master/机器学习/时间序列/https://github.com/daijiangtian/NoteBook/blob/master/机器学习/时间序列/images/blog/mathjax_logo.png?raw=true?raw=true?raw=true
---

当前可用的强大数据挖掘算法嵌入在黑盒软件中，会导致大量误用 
本文主要介绍主成分分析的流程 与 Python实践代码

<!-- more -->

### CRISP-DM 

#### 业务/研究理解阶段
- 根据延误或研究单元，从总体上清楚阐明目标和需求
- 将目标和约束转换为数据挖掘问题定义的公式
- 准备实现这些目标的初步策略


#### 数据理解阶段
- 收集数据
- 谈属性分析数据，发现浅层见解
- 评估数据质量
- 选择可执行模式的子集

#### 数据准备阶段
- 收集数据
- 选择变量
- 数据清洗 

#### 建模阶段 
- 使用适当的建模技术
- 校准模型设置以优化结果
- 可能要返回数据准备阶段，一边数据能够符合数据挖掘技术

#### 评估阶段
- 确认模型是否完成了阶段1设定的目标集
- 确认业务或研究问题的重要组成部分是否未被清楚的解释
- 做出是否使用数据挖掘结果的决定

#### 部署阶段
- 建立报表

### 数据挖掘的任务

- 描述
- 评估
- 预测
- 分类
- 聚类
- 关联

### 数据预处理

#### 原始数据不完整含有噪声
- 过时或者沉余字段
- 缺失字段
- 离群字段
- 不适合模型的数据
- 与常识不一致的数据

#### 缺席与数据变换

- 数据清洗
    - 多不符合常理的字段做出合理的解释
- 缺失数据
    - 用指定常亮替换
    - 用字段均值替换
    - 随机生成一个数
    - 根据记录的特性估计一个替换值
- 错误识别分类
    - 有一些分类要保持一致性，在统计时候需要统一类别
- 识别离群值
    - 中心值
        - 均值
        - 中位数
        - 众数
    - 散布度量
       - 标准差 (SD)
       - 极差
       - 平均绝对偏差
       - 四分位差   
         - IQR = Q3 - Q1 
         - < Q1*1.5*IQR
         - \> Q3*1.5*IQR 

- 数据变换
    - min-max规范化
        - X-MIN(X)/MAX(X)-MIN(X)
    - Z-score标准化
        - X-MEAN(X) / SD(X)
        - 对倾斜度无影响
    - 小数定标规范化
        - x/ 10^d  （d为最大值的位数）
- 正太转换
    - 一些数据挖掘和统计的算法需要数据呈现正太分布
    - 倾斜度
        - 3（均值-中位数）/ SD
    - 消除倾斜
        - 对数变换 ln(weight)
        - 平方根变化 根号(weight)
        - 平方根倒数 1 / 根号(weight)
    - 检查正太化
        - 构建正太概率图   
- 分类问题数值化
    - 对于有大小比较问题可以直接一维数值化
    - 对于无法比较问题用 one-hot 编码
    
- 脏数据
    - 删除无用变量 （1维常量）
    - 删除重复数据

- 可能不应该删除
    - 包含很多缺失值
    - 有较强相关性

### pca 降维

#### 数据降维的必要性

多重共线性会导致解空间不稳定，可能导致结果不连贯

#### 降唯的目标
- 减少预测变量的个数
- 帮助确保这些预测变量相互独立
- 提供一个框架解释结果

#### 规范化数据
使每个变量的均值为0，标准差为1 
```python
import numpy as np

dataset= {
    "a1":[1,2,3,6,4,5,9,5,1,2,2],
    "a2": [1, 2, 3, 6, 4, 5, 9, 5, 1, 2, 2],
    "a3": [1, 2, 3, 6, 4, 5, 9, 5, 1, 2, 2],
    "a4": [1, 2, 3, 6, 4, 5, 9, 5, 1, 2, 2]

}
data = pd.DataFrame(data=dataset, dtype=np.float)
from pprint import pprint
pprint((data - data.min()) / (data.max() - data.min()))  # 最小-最大规范化
pprint((data - data.mean()) / data.std())  # 零-均值规范化
```

#### 协方差矩阵 与 相关系数矩阵
```python
#返回一个协方差矩阵 
#衡量两个变量之间的同事变化的变化程度
print(data.cov())

#返回一个相关系数矩阵
#使用标准差对协方差进行缩放 对于标准数据集 方差均为1  协方差矩阵和相关系数矩阵相同
pprint(data.corr())
```

#### 成分矩阵

```python
#coding=utf-8
from numpy import *

'''通过方差的百分比来计算将数据降到多少维是比较合适的，
函数传入的参数是特征值和百分比percentage，返回需要降到的维度数num'''
def eigValPct(eigVals,percentage):
    sortArray=sort(eigVals) #使用numpy中的sort()对特征值按照从小到大排序
    sortArray=sortArray[-1::-1] #特征值从大到小排序
    arraySum=sum(sortArray) #数据全部的方差arraySum
    tempSum=0
    num=0
    for i in sortArray:
        tempSum+=i
        num+=1
        if tempsum>=arraySum*percentage:
            return num

'''pca函数有两个参数，其中dataMat是已经转换成矩阵matrix形式的数据集，列表示特征；
其中的percentage表示取前多少个特征需要达到的方差占比，默认为0.9'''
def pca(dataMat,percentage=0.9):
    meanVals=mean(dataMat,axis=0)  #对每一列求平均值，因为协方差的计算中需要减去均值
    meanRemoved=dataMat-meanVals
    covMat=cov(meanRemoved,rowvar=0)  #cov()计算方差
    eigVals,eigVects=linalg.eig(mat(covMat))  #利用numpy中寻找特征值和特征向量的模块linalg中的eig()方法
    k=eigValPct(eigVals,percentage) #要达到方差的百分比percentage，需要前k个向量
    eigValInd=argsort(eigVals)  #对特征值eigVals从小到大排序
    eigValInd=eigValInd[:-(k+1):-1] #从排好序的特征值，从后往前取k个，这样就实现了特征值的从大到小排列
    redEigVects=eigVects[:,eigValInd]   #返回排序后特征值对应的特征向量redEigVects（主成分）
    lowDDataMat=meanRemoved*redEigVects #将原始数据投影到主成分上得到新的低维数据lowDDataMat
    reconMat=(lowDDataMat*redEigVects.T)+meanVals   #得到重构数据reconMat
    return lowDDataMat,reconMat
```
