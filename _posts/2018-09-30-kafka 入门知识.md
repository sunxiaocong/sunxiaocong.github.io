---
layout: post
title: "kafka 入门知识"
date: 2018-09-30
categories: kafka
tags: [kafka]
image: http://gastonsanchez.com/images/blog/mathjax_logo.png
---
本文主要记录一些kafka入门的基础知识
<!-- more -->

### kafka 简介
kafka是一种分布式的，基于订阅/发布模式的消息系统。类似于消息队列，它主要有三个比较关键的功能：  
* 订阅/发布消息
* 容错性
* 实时性  

它的设计目的在于：
* 以时间复杂度为O(1)的方式提供消息持久化能力,即使对TB级以上数据也能保证常数时间复杂度的访问性能。
* 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条以上消息的传输。
* 支持Kafka Server间的消息分区,及分布式消费,同时保证每个Partition内的消息顺序传输。
* 同时支持离线数据处理和实时数据处理。
* 支持在线水平扩展。

至于它如何实现这些，之后深入源码在进行分析。

### kafka 核心术语
* Broker: kafka集群中包含一个或者多个服务器，这种服务器称之为broker。
* Topic: 可以理解为消息的类别。如果把kafka看成是数据库的话，topic就是表。用户只要指定消费的topic，无需关系数据是保留在那些broker。
* Partition: 每个topic可能有1个或者多个partition,每个partition可能分部在不同的broker上。每个partition上保留的是这个topic部分的数据，数据在partition上是有序的。由于存在多个partition，因此消费数据的顺序不是数据产生的顺序，要严格按照数据产生的顺序消费的话，设置partition的值为1.
* Partition offset: 记录这条消息的起始位置。
* Replicas of partition: 副本是一个partition的备份。副本不会被消费者消费，副本只用于防止数据丢失，即消费者不从为follower的partition中消费数据，而是从为leader的partition中读取数据。
* Leader:每个Partition都会有一个到多个的备份，其中一个作为Leader负责读写和同步数据到其他备份。
* Follower:所有写请求都通过Leader路由，数据变更会广播给所有Follower，Follower与Leader保持数据同步。当leader挂掉之后，根据选举算法推选出新的leader。
* Producer：顾名思义，数据的生产者。
* Consume：数据的消费者，可以同时消费一个到多个topic。
* Consumer Group: 每个消费者属于一个特定的消费组，同一个消费者可以有多个消费者消费同一个topic，（当然这个取决于你partition的数据量，保证消费者数量小于等于partition数据量，消费才不会重复）。

### 创建python消费者
在kafka python包中有示例,创建一个消费者如下:

    from kafka import KafkaConsumer
    
    # To consume latest messages and auto-commit offsets
    consumer = KafkaConsumer('my-topic',
                             group_id='my-group',
                             bootstrap_servers=['localhost:9092'])
    for message in consumer:
        # message value and key are raw bytes -- decode if necessary!
        # e.g., for unicode: `message.value.decode('utf-8')`
        print ("%s:%d:%d: key=%s value=%s" % (message.topic, message.partition,
                                              message.offset, message.key,
                                              message.value))

在使用中有一些比较重要的参数在这边重点解释一下:  
* group_id: 消费者组名称，最好自己指定。不指定的话默认组容易被其他人误消费。
* bootstrap_servers : kafka集群地址。
* auto_offset_reset : 设置初始消费的位置。默认是latest最新的数据开始消费，当然你也可以指定从最老的数据消费，参数为earliest。
* max_poll_records  : 每次拉取的最大批次
* max_poll_interval_ms : 每次拉取最长时间
* session_timeout_ms : 使用Kafka的组管理工具时用于检测故障的超时。消费者会定期向经纪人发送心跳，以表明自己的活跃程度。如果在此会话超时过期之前代理没有接收到心跳，则代理将从组中删除该消费者并启动重新平衡。默认是10s（如果没有发送心跳可能遇到offset重置的问题，也就是说会重新开始消费数据。）


### 总结
kafka是学习的第一个消息队列中间件，市面上还有其他优秀的如RabbitMQ，Redis，ZeroMQ（号称最快）有机会学习一下。

### 链接
[kafka-python](https://kafka-python.readthedocs.io/en/master/apidoc/KafkaConsumer.html)   
[kafka 设计解析系列](https://www.infoq.cn/article/kafka-analysis-part-1)  
[kafka 官网](https://kafka.apache.org/quickstart)